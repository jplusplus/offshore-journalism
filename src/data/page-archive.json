{
  "uid": "archive",
  "category": "Solutions",
  "name": "Archiving, private and public efforts",
  "file": "https://docs.google.com/document/d/1GP4eJXjJnWbdCahgEbNcpJU15kzMsdz3li35ewBMA0k/pub",
  "excerpt": "Private and public efforts have been set up to archive web pages, but their achievements fall short of providing the public with a comprehensive and accessible repository.",
  "html": "<h2>Internet archives and public libraries</h2><p>The need to preserve content published on the web is almost as old as the web itself. As soon as 1996, the Internet Archive, a non-profit activity managed by a Silicon Valley entrepreneur, started collecting and archiving web pages (the interface that lets the public access them was published in 2001). The goal was and remains primarily cultural in nature. According to its own website, the Archive “help[s] preserve [online cultural] artifacts and create[s] an Internet library for researchers, historians, and scholars.” <sup><a du-smooth-scroll href=\"#ftnt1\" id=\"ftnt_ref1\">[1]</a></sup></p><p>Almost at the same time, public institutions recognized the need to preserve digital content. In 2003, UNESCO, the satellite institution of the United Nations tasked with cultural issues, had its members sign the Charter on the Preservation of Digital Heritage, which recognized the need to preserve digital content. In some countries, the Charter was followed by changes in national legislation regarding archiving, which adapted old texts to the new, digital reality.</p><p>Whether public or private, efforts to preserve web content follow two main directions. One is a large-scope, lacunary and open approach, and the other is a narrow-scope, comprehensive and closed one.</p><h2>The large-scope, lacunary approach </h2><p>The most well-known way to archive the web is the approach followed by the Internet Archive. Users can submit a URL to the Archive, the server of the archiving service makes a request to the server of the page to be saved and copies the content returned by the server, sometimes including part of the linked assets such as stylesheets and script files (needed to render the page in a web browser) and images, though additional content, especially content stored in sub-pages or iframes, PDF files or Flash programs, is not saved. This is of special concern when a website embeds a Youtube video, for instance, because the video itself will not be saved and can be deleted on Youtube by its owner or by the platform itself. </p><p>Another issue has to do with proxying. When a page is archived, the page itself is not transmitted to the archiving service by the user who wants to archive the page. Instead, the user asks the archiving service to query the page and save it. The content that is returned by the server hosting the target page does not transit via the user who initiated the request. Using the HTTP header “X-Forwarded-For”, the archiving service can signal to the target server who the final user is but the target server can be programmed to respond in a specific way to a request emanating from an archiving service. Such specific response used to be publicly coded in the robots.txt files. However, since the Internet Archive announced that it would ignore the contents of those files,<sup><a du-smooth-scroll href=\"#ftnt2\" id=\"ftnt_ref2\">[2]</a></sup> it is possible that servers that host content will change their strategies and code non-public scripts that prevent them from returning content to the archiving servers, or that return a different content from the one the user requesting the archiving sees. This issue is of particular concern for news content. Many news websites have paywalls in place, so that only logged in users can access the published content. The same is true of some content on walled-in platforms such as Facebook. In such cases, archiving services have no way to access the content to protect.</p><p><img src=\"https://docs.google.com/drawings/image?id=sqfOiWbrl7eAuBVYwlvPXlQ&amp;rev=1&amp;h=432&amp;w=601&amp;ac=1\" /></p><p>The Internet Archive is not the only organization enabling people to save webpages. Archive.is, a service that seems privately-run but whose owner and operator remains obscure, Teyit.link, a service set up in 2017 by Turkish verification platform Teyit.org, or Arquivo.pt, a service run by the Portuguese administration, work on the same model of archiving the open web and letting users submit a page for archiving and retrieving the archived version later. One service, Arquivo.pt, only lets users retrieve pages that have been archived more than a year previously, in order not to cannibalize the traffic of news websites.</p><p>Some services – the Internet Archive and Arquivo.pt – operate automated crawls of portions of the web independently of requests by users. They crawl lists of websites that have been deemed worthy of being archived, such as government websites or news publications.</p><p>Because of their large scope, such services rarely, if ever, preserve the entirety of an online property. When digital news outlets disappear, the holes in coverage show, and they can be huge. In January 2017, for instance, the main digital-only newsroom in Portugal, <em>Diário Digital</em>, was shut down by its publisher for financial reasons.<sup><a du-smooth-scroll href=\"#ftnt3\" id=\"ftnt_ref3\">[3]</a></sup> <em>Diário Digital</em> had been the largest and oldest online newsroom in the country and had operated continuously since 1999. It had no paywall and no specific robots.txt instruction that could have hampered archiving. Despite these advantages, most of the content of <em>Diário Digital</em> is not to be found on the Internet Archive or Arquivo.pt. No study has been made to know how many articles published by <em>Diário Digital</em> in its 17 years of operation have been lost or how important they were.</p><h2>The narrow-scope, comprehensive approach</h2><p>To prevent such losses, the second approach to archiving the web aims at being comprehensive. It is based on the concept of legal deposit which, in some countries, states that public libraries must archive all newspapers and books published anywhere on the territory. Such laws date back to the introduction of the printing press and their purpose was as much cultural preservation as control and censorship (by forcing publishers to send a copy of each issue to the national library, a country’s ruler could oversee all content being published).<sup><a du-smooth-scroll href=\"#ftnt4\" id=\"ftnt_ref4\">[4]</a></sup></p><p>Legal deposit laws were adapted in the 2000’s to encompass online content. Since then, many national libraries archive all content from most publishers under their national jurisdiction. Libraries make lists of websites that need to be archived, usually all websites under the national top-level domain name (e.g. all websites ending in “.fr” or “.dk”) and specify how often the websites need to be saved, which can be as rarely as every year for unimportant websites to several times a day for newspapers. While the list of domains to preserve is in itself political,<sup><a du-smooth-scroll href=\"#ftnt5\" id=\"ftnt_ref5\">[5]</a></sup> this approach solves some of the limitations of the first one. Because of the legal obligation to archive content, publishers must cooperate with librarians: they must give access to paywalled articles and cannot block the crawlers of the national library. However, the technical limitations of crawling remain. Videos, content published on third-party websites (Facebook, Vine, Youtube etc.) and special applications such as infographics are not archived. One person interviewed for this report said that videos might be archived starting in 2018, though he could not be sure.</p><p>More importantly, such archives are not publicly accessible. In France, for instance, the archived content can only be accessed from the national library itself. In Denmark, people requesting access to the archived content must be vetted (this is justified by the possibility that some of the archived content <em>could</em> contain personal information). As such, these archives barely comply with Art. 9 of the above-mentioned Charter on the Preservation of Digital Heritage, which states in that Article that the preserved content should be made accessible.</p><p></p><hr /><div><p><a du-smooth-scroll href=\"#ftnt_ref1\" id=\"ftnt1\">[1]</a> <a href=\"https://www.google.com/url?q=http://archive.is/kd8Ca&amp;sa=D&amp;ust=1497952923932000&amp;usg=AFQjCNFINxWin5DKzvLS-07zTh1209StKg\">Why is the Internet Archive collecting sites from the Internet? What makes the information useful?</a>, FAQ, Internet Archive,  <a href=\"https://www.google.com/url?q=https://archive.org/about/faqs.php%2321&amp;sa=D&amp;ust=1497952923933000&amp;usg=AFQjCNG-ByrSUUUTwPSYACA_BTfTXgDePQ\">https://archive.org/about/faqs.php#21</a> </p></div><div><p><a du-smooth-scroll href=\"#ftnt_ref2\" id=\"ftnt2\">[2]</a> Mark Graham, <a href=\"https://www.google.com/url?q=http://archive.is/oIPbM&amp;sa=D&amp;ust=1497952923935000&amp;usg=AFQjCNFWNrKeh51VfCCgcY8-3WoN8B6H1Q\">Robots.txt meant for search engines don’t work well for web archives</a>, Internet Archive Blogs, </p><p><a href=\"https://www.google.com/url?q=http://blog.archive.org/2017/04/17/robots-txt-meant-for-search-engines-dont-work-well-for-web-archives/&amp;sa=D&amp;ust=1497952923936000&amp;usg=AFQjCNHDtgNeSU-cJ8IVsjPQ9ZwyCEKf_A\">http://blog.archive.org/2017/04/17/robots-txt-meant-for-search-engines-dont-work-well-for-web-archives/</a> </p></div><div><p><a du-smooth-scroll href=\"#ftnt_ref3\" id=\"ftnt3\">[3]</a> <a href=\"https://www.google.com/url?q=http://archive.is/gNqvJ&amp;sa=D&amp;ust=1497952923937000&amp;usg=AFQjCNHDtO9n_G7kwO6VGASUzqabmRZEBA\">Diário Digital online news service shuts down</a>, AlgarveDailyNews.com, January 9, 2017 ( <a href=\"https://www.google.com/url?q=http://www.algarvedailynews.com/news/10777-diario-digital-online-news-service-shuts-down&amp;sa=D&amp;ust=1497952923938000&amp;usg=AFQjCNFZQMx6PLYNKnef7XTwaduT2Wu6Sw\">http://www.algarvedailynews.com/news/10777-diario-digital-online-news-service-shuts-down</a> ) </p></div><div><p><a du-smooth-scroll href=\"#ftnt_ref4\" id=\"ftnt4\">[4]</a> In France, legal deposit started in 1537 with the Ordonnance de Montpellier, for instance. See : Magali Vène, <a href=\"https://www.google.com/url?q=http://archive.is/7ddvJ&amp;sa=D&amp;ust=1497952923940000&amp;usg=AFQjCNHNm21juwhTgoaOg6EgF76tFBndlQ\">L'Ordonnance de Montpellie</a>r, Exposition François Ier, Bibliothèque nationale de France, (<a href=\"https://www.google.com/url?q=http://expositions.bnf.fr/francoisIer/arret/06-4.htm&amp;sa=D&amp;ust=1497952923941000&amp;usg=AFQjCNGceztHQ-jRfaMhDY1acs-1KgXQ6A\">http://expositions.bnf.fr/francoisIer/arret/06-4.htm</a>)</p></div><div><p><a du-smooth-scroll href=\"#ftnt_ref5\" id=\"ftnt5\">[5]</a> Valérie Schafer,<a href=\"https://www.google.com/url?q=http://archive.is/D2HPl&amp;sa=D&amp;ust=1497952923943000&amp;usg=AFQjCNFziFzUXr9O-yMhBfoPZIw0JTNmxw\"> Archives : comment le Web devient patrimoine</a>, TheConversation.com, April 24, 2017 ( <a href=\"https://www.google.com/url?q=https://theconversation.com/archives-comment-le-web-devient-patrimoine-76487&amp;sa=D&amp;ust=1497952923944000&amp;usg=AFQjCNHtUe5Ufj3GPR8PcsyQqcrd0KiJEw\">https://theconversation.com/archives-comment-le-web-devient-patrimoine-76487</a> )</p></div>"
}