{
  "uid": "future-work",
  "category": "Solutions",
  "name": "Possible future work",
  "file": "https://docs.google.com/document/d/1zO8Lq74OuJGyqhCyRGNS0j7WJJSL_uYxkXib3jiRAak/pub",
  "excerpt": "The way forward to offshore journalism and maximize freedom.",
  "html": "<p>Possible future work</p><p>This preliminary report is part of the larger Offshore Journalism Toolkit project set up to find ways to preserve legitimate journalistic content at risks of being deleted. Researching the issues and talking to stakeholders we have tentatively identified three possible avenues for further work, we propose to discuss them publicly, as they be developed both within and outside the project itself.</p><h2>Guidelines for deletion</h2><p>The interviews we led to prepare this report showed that all newsrooms, as well as some archiving services, face requests for deletion, court orders mandating the removal of a piece of content or cease-and-desist letters from lawyers. The frequency of such requests range from once a year to several times a week. The decision process to deal with such requests was, in every case, arbitrary. In most cases, the judgement of the editor-in-chief or her deputy was the only determinant for deletion or preservation, after consideration of the balance between legal risk and newsworthiness. One newsroom published a transparency report but stopped doing so after it acknowledged a lack of interest from their stakeholders.</p><p>To increase accountability and foster transparency, newsrooms could be helped in establishing clear guidelines for deletion, which journalists, readers and researchers could consult to better understand the deletion process. Tools to facilitate the production of transparency reports could be created to decrease the costs of such products and prevent their being removed after a first try in case of lack of interest.</p><h2>A metatag standard for archiving</h2><p>This report has shown that current archiving options were too expensive for publishers, who do not wish to set up copies of their content ‒ when they are not legally prevented to do so ‒ and that open archiving platforms could not preserve important articles, were it only because they do not know what content should be archived and what should not. Importantly, publishers cannot archive a piece of content once they have been asked to remove it; it would constitute contempt of court in case of a court-mandated order or the assurance of further trouble in case of a cease-and-desist letter.</p><p>As information architect Federico Badaloni first suggested to the authors,<sup><a du-smooth-scroll href=\"#ftnt1\" id=\"ftnt_ref1\">[1]</a></sup> a solution to this double problem (lack of resources to set up mirrors and impossibility to create a copy after a request for deletion) would be for newsworthy content published online to have an HTML metatag that would indicate to crawlers what should be archived, what type of content (text and/or video) should be archived and what level of priority it has. With a such standard in place, crawlers created by third parties could ask archiving services to make a copy of a specific page, including its multimedia content if need be.</p><p>If a publisher feels that a piece of content is at risk of being removed, it could change the value of the metatag to indicate that the piece should be archived. Such changes could be done automatically, for all articles published by the news outlet which contain original content, for instance. While a crawler could archive all content from a specific section, such as Crime, Politics or Finance, it would archive needlessly all the articles that are made from press releases or news wires, thereby jamming the pipes of the archiving services. A metatag would solve this issue.</p><p>A metatag that could specify if the multimedia content of a page (e.g. a Youtube video, an interactive app, a PDF or an audio segment) requires protection would let a crawler direct the content to the most adequate archiving service (e.g. the “moving image archive” of the Internet Archive for video).</p><p>With such a metatag, the publisher takes no legal risk as it did not initiate the copy process. In case of an order to remove the piece of content, the publisher would be able to remove it without hampering its archived version, of which they have no knowledge.</p><h2><img src=\"https://docs.google.com/drawings/image?id=s7XlJs8yheal5m57klbj8xA&amp;rev=1&amp;h=326&amp;w=556&amp;ac=1\" /><br /><br />A “search &amp; rescue” network</h2><p>An open discussion and a subsequent agreement among stakeholders about the meta-description of journalistic items deemed at risk of deletion may trigger a wider discussion on what to do with “flagged” content, how do it, and who should do it. </p><p>One idea worth exploring is the creation of a “search and rescue” organization or network, somehow borrowed by what happens at sea: the activated metatag would be interpreted as a distress signal to be answered by either a passing ship or an institutionally dedicated organization like the Coast Guard.</p><ul><li>The “passing ship” could be any publication willing to host the content at risk, for a limited or an unlimited amount of time, according to established rules.</li><li>The “Coast Guard” could be a consortium (or more than one), able to pool technical, human and legal resources in order to institutionalize the process and offer support. The consortium/network could be formed by publishing companies, journalism organizations, NGOs, civil rights associations and institutions like libraries and archives.</li></ul><p></p><p>A public discussion should include rules about what to save and how, the legal property status of the “saved” content, and also rules about the organization itself, namely how to protect publishers and newsrooms, while at the same time assuring that they may still have a say in what happens with the content they originally produced. </p><p></p><hr /><div><p><a du-smooth-scroll href=\"#ftnt_ref1\" id=\"ftnt1\">[1]</a> Telephone interview, April 8, 2017, and subsequent talks in person.</p></div>"
}